{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39SaanZOvgbx",
        "outputId": "dd43788f-c85c-4816-d22e-65421bf653d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9648 - mae: 0.7349 - val_loss: nan - val_mae: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7207 - mae: 0.5777 - val_loss: nan - val_mae: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6252 - mae: 0.5415 - val_loss: nan - val_mae: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6251 - mae: 0.5346 - val_loss: nan - val_mae: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6372 - mae: 0.5327 - val_loss: nan - val_mae: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6490 - mae: 0.5261 - val_loss: nan - val_mae: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6130 - mae: 0.5179 - val_loss: nan - val_mae: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6468 - mae: 0.5243 - val_loss: nan - val_mae: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6251 - mae: 0.5196 - val_loss: nan - val_mae: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6324 - mae: 0.5175 - val_loss: nan - val_mae: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6129 - mae: 0.5118 - val_loss: nan - val_mae: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5954 - mae: 0.5068 - val_loss: nan - val_mae: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6291 - mae: 0.5126 - val_loss: nan - val_mae: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6171 - mae: 0.5128 - val_loss: nan - val_mae: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6535 - mae: 0.5165 - val_loss: nan - val_mae: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6082 - mae: 0.5081 - val_loss: nan - val_mae: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5921 - mae: 0.5031 - val_loss: nan - val_mae: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5816 - mae: 0.4991 - val_loss: nan - val_mae: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6232 - mae: 0.5051 - val_loss: nan - val_mae: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6107 - mae: 0.5056 - val_loss: nan - val_mae: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5777 - mae: 0.4998 - val_loss: nan - val_mae: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6143 - mae: 0.5063 - val_loss: nan - val_mae: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6171 - mae: 0.5010 - val_loss: nan - val_mae: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6230 - mae: 0.5058 - val_loss: nan - val_mae: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6170 - mae: 0.5032 - val_loss: nan - val_mae: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6118 - mae: 0.5018 - val_loss: nan - val_mae: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6000 - mae: 0.4975 - val_loss: nan - val_mae: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6499 - mae: 0.5052 - val_loss: nan - val_mae: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6254 - mae: 0.5011 - val_loss: nan - val_mae: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6164 - mae: 0.5058 - val_loss: nan - val_mae: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5975 - mae: 0.4969 - val_loss: nan - val_mae: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6073 - mae: 0.4999 - val_loss: nan - val_mae: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6179 - mae: 0.5017 - val_loss: nan - val_mae: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6126 - mae: 0.5019 - val_loss: nan - val_mae: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6174 - mae: 0.5012 - val_loss: nan - val_mae: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6168 - mae: 0.4995 - val_loss: nan - val_mae: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6046 - mae: 0.4976 - val_loss: nan - val_mae: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6150 - mae: 0.4983 - val_loss: nan - val_mae: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6346 - mae: 0.5013 - val_loss: nan - val_mae: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6568 - mae: 0.5040 - val_loss: nan - val_mae: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5875 - mae: 0.4919 - val_loss: nan - val_mae: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6202 - mae: 0.4998 - val_loss: nan - val_mae: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6118 - mae: 0.4939 - val_loss: nan - val_mae: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6295 - mae: 0.5010 - val_loss: nan - val_mae: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5862 - mae: 0.4955 - val_loss: nan - val_mae: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5853 - mae: 0.4909 - val_loss: nan - val_mae: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6248 - mae: 0.5021 - val_loss: nan - val_mae: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6092 - mae: 0.4965 - val_loss: nan - val_mae: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6147 - mae: 0.4971 - val_loss: nan - val_mae: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5739 - mae: 0.4899 - val_loss: nan - val_mae: nan\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan\n",
            "Test Loss: nan, Test MAE: nan\n"
          ]
        }
      ],
      "source": [
        "# Objective (a): Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Objective (b): Upload / access the dataset\n",
        "# Load and preprocess the dataset\n",
        "file_path = '/content/sample_data/ecg.csv'  # Update with your file path in Colab\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Objective (c): Encoder converts it into latent representation\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 64  # Latent space size\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "\n",
        "# Objective (d): Decoder networks convert it back to the original input\n",
        "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
        "\n",
        "# Build the autoencoder model\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "# Objective (e): Compile the models with Optimizer, Loss, and Evaluation Metrics\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Train the model\n",
        "history = autoencoder.fit(X_train, X_train,\n",
        "                          epochs=50,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(X_test, X_test))\n",
        "\n",
        "# Evaluate model performance\n",
        "loss, mae = autoencoder.evaluate(X_test, X_test)\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n"
      ]
    }
  ]
}